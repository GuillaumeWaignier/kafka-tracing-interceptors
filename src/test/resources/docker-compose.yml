version: "3.7"
services:
  zookeeper:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    container_name: zookeeper
    hostname: zookeeper
    command: zookeeper-server-start
    networks:
      - confluent
    environment:
      - KAFKA_SERVER_ID=1
      - KAFKA_clientPort=2181
      - KAFKA_dataDir=/tmp/zookeeper
      - KAFKA_tickTime=2000
      - KAFKA_4lw_commands_whitelist=stat, ruok, conf, isro
      - KAFKA_OPTS=-Xms128m -Xmx128m
    restart: on-failure
    healthcheck:
      test: test `echo "ruok" | nc localhost 2181 | grep "imok"`
      interval: 2s
      timeout: 2s
      retries: 3
      start_period: 2s

  kafka:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    container_name: kafka
    hostname: kafka
    command: kafka-server-start
    ports:
      - 9092:9092
    networks:
      - confluent
    depends_on:
      - zookeeper
    environment:
      - KAFKA_broker_id=101
      - KAFKA_zookeeper_connect=zookeeper:2181
      - KAFKA_listener_security_protocol_map=PLAINTEXT:PLAINTEXT
      - KAFKA_advertised_listeners=PLAINTEXT://kafka:9092
      - KAFKA_listeners=PLAINTEXT://:9092
      - KAFKA_inter_broker_listener_name=PLAINTEXT
      - KAFKA_auto_create_topics_enable=true
      - KAFKA_delete_topic_enable=true
      - KAFKA_offsets_topic_replication_factor=1
      - KAFKA_OPTS=-Xms256m -Xmx256m
      - KAFKA_num_partitions=3
    restart: on-failure
    healthcheck:
      test: nc -z localhost 9092
      interval: 2s
      timeout: 2s
      retries: 3
      start_period: 2s

  schema-registry:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    container_name: schema-registry
    hostname: schema-registry
    command: schema-registry-start
    depends_on:
      - kafka
    ports:
      - 8081:8081
    networks:
      - confluent
    environment:
      - SCHEMA_REGISTRY_OPTS=-Xms256m -Xmx256m
      - KAFKA_listeners=http://0.0.0.0:8081
      - KAFKA_host_name=schema-registry
      - KAFKA_kafkastore_connection_url=zookeeper:2181
      - KAFKA_kafkastore_bootstrap_servers=PLAINTEXT://kafka:9092
      - KAFKA_kafkastore_security_protocol=PLAINTEXT
      - KAFKA_kafkastore_topic_replication_factor=1
      - KAFKA_default_replication_factor=1
    restart: on-failure
    healthcheck:
      test: test `curl -s -o /dev/null -w "%{http_code}" http://localhost:8081` = 200
      interval: 2s
      timeout: 2s
      retries: 3
      start_period: 2s


  kafkahq:
    image: tchiotludo/kafkahq:0.12.0
    container_name: kafkahq
    networks:
      - confluent
    ports:
      - "8080:8080"
    environment:
      KAFKAHQ_CONFIGURATION: |
        kafkahq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka:9092"
              schema-registry:
                url: "http://schema-registry:8081"
              connect:
                - name: default
                  url: "http://kafka-connect:8083"


  load-data-p1:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    networks:
      - confluent
    depends_on:
      - kafka
    entrypoint: "kafka-producer-perf-test --topic test --num-records 1000000 --throughput ${THROUGHPUT} --record-size 100 --producer-props interceptor.classes=org.ianitrix.kafka.interceptors.ProducerTracingInterceptor bootstrap.servers=kafka:9092 client.id=myProducer1"
    volumes:
      - ../../../target/tracing-interceptors-0.0.1-SNAPSHOT-jar-with-dependencies.jar:/confluent-${CONFLUENT_VERSION}/share/java/kafka/tracing-interceptors.jar:ro
    restart: on-failure

  load-data-p2:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    networks:
      - confluent
    depends_on:
    - kafka
    entrypoint: "kafka-producer-perf-test --topic test --num-records 1000000 --throughput 2 --record-size 100 --producer-props interceptor.classes=org.ianitrix.kafka.interceptors.ProducerTracingInterceptor bootstrap.servers=kafka:9092 client.id=myProducer2"
    volumes:
      - ../../../target/tracing-interceptors-0.0.1-SNAPSHOT-jar-with-dependencies.jar:/confluent-${CONFLUENT_VERSION}/share/java/kafka/tracing-interceptors.jar:ro
    restart: on-failure

  load-data-no-interceptor:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    networks:
      - confluent
    depends_on:
      - kafka
    entrypoint: "kafka-producer-perf-test --topic test --num-records 1000000 --throughput 1 --record-size 100 --producer-props bootstrap.servers=kafka:9092 client.id=myProducerNoInterceptor"
    restart: on-failure

  consume-data-c1:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    networks:
      - confluent
    depends_on:
      - kafka
    entrypoint: "kafka-console-consumer --topic test --from-beginning  --consumer-property interceptor.classes=org.ianitrix.kafka.interceptors.ConsumerTracingInterceptor --bootstrap-server kafka:9092 --consumer-property client.id=myConsumer1 --group=myGroup1"
    volumes:
      - ../../../target/tracing-interceptors-0.0.1-SNAPSHOT-jar-with-dependencies.jar:/confluent-${CONFLUENT_VERSION}/share/java/kafka/tracing-interceptors.jar:ro
    restart: on-failure

  consume-data-c2:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    networks:
      - confluent
    depends_on:
      - kafka
    entrypoint: "kafka-console-consumer --topic test --from-beginning  --consumer-property interceptor.classes=org.ianitrix.kafka.interceptors.ConsumerTracingInterceptor --bootstrap-server kafka:9092 --consumer-property client.id=myConsumer2 --group=myGroup2"
    volumes:
      - ../../../target/tracing-interceptors-0.0.1-SNAPSHOT-jar-with-dependencies.jar:/confluent-${CONFLUENT_VERSION}/share/java/kafka/tracing-interceptors.jar:ro
    restart: on-failure

  consume-data-over:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    networks:
      - confluent
    depends_on:
      - kafka
    entrypoint: "/overConsumption.sh kafka:9092 2000"
    volumes:
      - ../../../target/tracing-interceptors-0.0.1-SNAPSHOT-jar-with-dependencies.jar:/confluent-${CONFLUENT_VERSION}/share/java/kafka/tracing-interceptors.jar:ro
      - ./overConsumption.sh:/overConsumption.sh:ro
    restart: on-failure

networks:
  confluent:
    name: confluent
